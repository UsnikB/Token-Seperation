# Token-Seperation
Lexical Analysis
Scanning is the first phase of a compiler in which the source program is read character by character and then grouped in to various tokens.
Token is defined as sequence of characters with collective meaning. The various tokens could be identifiers, keywords, operators, 
punctuations, constants, etc. The input is a program written in any high level language and the output is stream of tokens. 
Regular expressions can be used for implementing this token separation.
